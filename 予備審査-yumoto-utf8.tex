%\documentclass[12pt,a4j]{jreport}
\documentclass[a4paper,12pt]{jreport}
%\usepackage[dvips]{graphicx,color}
%\usepackage{array}main
%\usepackage{amsmath,amsthm,amssymb}
%\usepackage{refcheck}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{eepic,eepicsup}
\setlength{\columnsep}{4mm}
\setlength{\parskip}{1.4mm}

\usepackage[dvipdfmx]{graphicx}
\usepackage{url}

\usepackage[fleqn]{amsmath}

\usepackage{caption}
\usepackage{flushend}

%excel2latex用に追加
\usepackage{multirow}
\usepackage{bigstrut}


%筑波大学のフォーマットからコピー
\usepackage{times} % use Times Font instead of Computer Modern

\setcounter{tocdepth}{3}
\setcounter{page}{-1}

\setlength{\oddsidemargin}{0.1in}
\setlength{\evensidemargin}{0.1in}
\setlength{\topmargin}{0in}
\setlength{\textwidth}{6in}
%\setlength{\textheight}{10.1in}
\setlength{\parskip}{0em}
\setlength{\topsep}{0em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% タイトル生成用パッケージ(重要)
%\usepackage{sie-jp-sjis}
\usepackage{sie-jp-utf}

%% タイトル
%% 【注意】タイトルの最後に\\ を入れるとエラーになります
\title{テスト対象の機能構造とデータの入出力情報を使ったブラックボックステスト手法の研究}
%% 著者
\author{湯本剛}
%% 学位 (2012/11 追加)
%\degree{}
%% 指導教員
%\advisor{}

%% 専攻名 と 年月
%% 年月は必要に応じて書き替えてください。
%\majorfield{△△△△}\programfield{□□□□}
\yearandmonth{2017年10月}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle
\thispagestyle{empty}
\newpage

\thispagestyle{empty}
\vspace*{20pt plus 1fil}
\parindent=1zw
\noindent
%%
%% 論文の概要(Abstract)
%%%
%\begin{center}
%{\bf 概要}
%\vspace{5mm}
%\end{center}


%%%%%
\par
\vspace{0pt plus 1fil}
\newpage

\pagenumbering{roman} % I, II, III, IV
\tableofcontents
\listoffigures
\listoftables

\pagebreak \setcounter{page}{1}
\pagenumbering{arabic} % 1,2,3

%%%%%%%%%%%%%%%%%%%%%%%
\chapter{序論}
ソフトウェア開発の中の品質を確保する主要な技術として,ソフトウェアテストがある．
昨今のソフトウェアの複雑性と規模の急激な増加に伴い，求められるテストケースの数も増加の一途をたどっている．
ブラックボックステストの場合，ソフトウェアの規模とテストケース数の関係は，ファンクションポイント総計値の1.15乗から1.3乗となる\cite{jones1998estimating}．
開発プロジェクトのファンクションポイント総計値は1970年から2000年までの30年間で約10倍の増加を示している\cite{longstreet2000}．
テストケース数の増加に対応するために必要となるテスト工数は，ソフトウェア開発工数の多くを占めるようになって来ている．
日本のソフトウェア開発において,ソフトウェアテストは開発工数全体の28％から35％を占めるという調査結果が出ている．
また，調査結果の中には，90％以上を占めるという事例もある\cite{IPA2015}．
ソフトウェアテストの活動のうち，テスト実行工程がソフトウェア開発のクリティカルパス上にある唯一の工程となる．
テスト実行の前にテストケースを開発し，実行するテストの全体像を示せると，効率のよいテスト実行を計画できる．
テストケースの開発はテスト工数全体の40パーセントを占めると言われている\cite{van2013tpi}．
これは，テストケースの開発に多くの人員が投入されていることを示している．
多数の人員がテスト開発の活動に投入されているにもかかわらず， テスト開発のための明確に定義されたルールがなく，個々の考え方に基づいてテストを開発することが多い．
これはテストケースの重複や漏れの原因となる可能性がある．
本研究では，テストケースを開発する際の重複や漏れを解決することを目的とし，テストケースを開発するための手法を検討する．２章では，研究対象であるシステムテストにおけるブラックボックステストにおける課題と先行研究を調査し，３章では，テスト分析手法の提案と実験による提案手法の評価を行なった．４章では，３章にて提案した分析手法の具体的な適用方法としてテストデータの入出力に着目した手法の提案と適用評価を行った．5章では，分析手法を適用する１つの領域で起きる、状態遷移の組合せによるテストケース数の爆発に対処し，重要なテストケースを抽出する方法を提案し，適用評価を行なった．
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\chapter{ブラックボックステストにおけるテスト分析とその課題}
\section{本研究の対象となるテストケースの開発方法とテストレベル}
\subsection{テストケースの開発方法}
テストケースを開発する方法は，ソフトウェアの構造を基にテスト設計するホワイトボックステストと，ソフトウェアの仕様を基にテスト設計するブラックボックステストに大別できる\cite{myers2011art} ．
ホワイトボックステストはテスト設計のベースがソースコードのようなテスト対象そのものとなるため，テスト対象プログラムの行を網羅，分岐を網羅といった具合にテストにて網羅すべきアイテムを明確に選択することが容易である．
網羅基準はテスト設計技法として提唱されている\cite{myers2011art}．
一方，ブラックボックステストでは，テスト対象そのものではなく，テスト対象の動作条件や振る舞いについて記述した仕様をベースにしてテストケースを開発する．
ブラックボックステストのテスト設計技法の中で、仕様に対する網羅基準は，ホワイトボックステスト同様数多く提唱されている\cite{myers2011art}．
しかし，ブラックボックステストは，テストベースがAUTの物理的な構造ではなく論理的なふるまいの記述であるがゆえに，テストを作るための詳細化が複数の解釈で行われることが多い\cite{yumoto2013test}．
%しかし，ブラックボックステストのためのテスト分析は詳細化に一貫性がないことが多く，それがゆえにテストケースの漏れや重複が起きることも多い．本提案では，テスト対象とフォールトを知識化したテストカテゴリを用いて一貫性のあるテスト分析手法を提案する．
結果的にテストケースの重複や抜け漏れを引き起こす可能性も高くなる．
本研究では，ブラックボックステストを対象とする．
\subsection{テストレベル}
ソフトウェアテストは，開発ライフサイクルの中で複数のテストレベルに分けて行われる．
%複数のテストレベルは，図~\ref{fig:D-2-Fig1}で示すVモデルと呼ばれる技術面にフォーカスしたサイクルモデルにて表現することができる\cite{arnold1996software}．
各テストレベルはソフトウェア開発の段階的詳細化のレベルと対応している．
本研究は，複数のレベルの中で，赤枠で囲んだシステムレベルの検証で行われるブラックボックステストに焦点を当てている．
システムレベルのテストは，開発した単体のソフトウェアがすべて統合されるため，規模の増大と複雑性の増加の影響を直接的に受けるからである．
%\begin{figure}[h]
%  \begin{center}
%   \includegraphics[width=12cm]{./image/D-2-Fig1.png}
%   \caption{Vモデル}
%   \label{fig:D-2-Fig1}
%  \end{center}
%\end{figure}

\section{テスト分析}
Vモデルであらわす各レベルにて行われるテストはそれぞれ，開発プロセスと類似したプロセスを持っている [4].
テストのプロセスは, 図~\ref{fig:D-2-Fig2}のようにテスト計画がVモデルの左側の活動と並行に行われ，その後時系列にテスト分析，テスト設計，テスト実装が行われた後，Vモデルの右側の活動の中で，テスト実行と終了基準の評価が行われる．
また，テストプロセスの中でもテスト分析，テスト設計，テスト実装の3つの活動はテスト開発プロセスとも呼ばれている[5] ．
テスト設計の際には，テスト設計技法が適用できるサイズにテスト対象を詳細化することが必要となる．この活動はテスト分析と呼ばれている．
% ブラックボックステストを設計するベースとなる仕様とは，図1で示したVモデルの左側の成果物のことである．
% 各検証のレベルでテスト設計のベースする仕様はテストベースと呼ばれている[5]．
% 本提案の対象となるV字モデルのレベルでは図2のsystem performance specificationがテストベースとなる．
% テストベースとなる仕様書は，その後の工程である設計やコーディングといった活動のために記載されるものであるため，テスト設計技法を適用する1つのアイテムに対する仕様が複数個所に分散して記載されてしまうことが多い．
% また，記述が自然言語であることも多く，条件の組み合わせや順序についての記述が不足していることも多い．
% テスト分析はこのようなテストベースに対して，何らかの考え方に基づき，テストにて網羅すべきアイテムを選択し，整理する活動である．
テスト分析は，図~\ref{fig:D-2-Fig2}で示すとおり，テスト開発プロセス中の最初の活動である．
\begin{figure}[h]
  \begin{center}
   \includegraphics[width=12cm]{./image/D-2-Fig2.png}
   \caption{テストプロセスとテスト開発プロセス}
   \label{fig:D-2-Fig2}
  \end{center}
\end{figure}

\subsection{テスト分析の課題}
テスト分析の活動の出力となるテスト条件は，機能，トランザクション，品質特性，構造的要素といった多くの側面の総称であるため，各側面の関係を整理するための構造化が必要である．
しかし，テスト分析におけるテスト条件群の構造化は，研究や実務においても，経験則や個人の考え方に基づく構造化に留まっている [6]．
一般的には，テストベースを表1のように大項目，中項目，小項目と詳細化していくことが多い．
この方法は，詳細化する際の各分類項目に明確なルールが定義されていないため，個人毎の何かしらの考え方で詳細化するための分類を決めていくことになる．
そのため，分類にばらつきが発生し，同じテスト条件が複数の階層に現れてしまったり，同じ意味のテスト条件が別の名称で選択されるといった混乱が起きてしまう．
この結果は複数の個人がそれぞれ複数の結果に到達することを示している．
%The different results mean a great variance in test conditions determined through test analysis.
複数の結果とは，テスト分析を通して特定したテスト条件にばらつきがあることを意味している．
%Thus, when the test analysis is performed by many individuals there is a high chance for test conditions to either be duplicated or even missed out entirely.
したがって，テスト分析が多くの人たちで行われるときには，テスト条件の重複，もしくは完全に抜け落ちるといった可能性が非常に高くなる．
テスト開発の最初の活動であるテスト分析にて特定するテスト条件にこのような問題があるとその後の活動で作られるテストケースの抜け漏れ，重複に大きく影響を及ぼす．

\subsection{ブラックボックステストにおけるテスト分析の先行研究}
ISTQBでは，テスト分析を実行するための要求事項や必要性は述べている．
けれども，テストベースを分析していくためのアプローチは定義されていない．
これは，Ostrand [8]， Grindal [9]などのテスト開発に関する先行研究でも同様である．
更に言うと，G.J.MyersやB.Beizerといった先行研究の多くは，テスト分析にてテスト条件が特定された後に適用されるテストパラメータの設計に焦点を当てている．
そのため，テスト条件は，すでに全て準備されたと言う前提になっている.
%Some studies on the test analysis method have also been proposed by Nishi [12], Akiyama [13], etc.
テスト分析手法に関する研究は，Nishi [12]， Akiyama[13]などがある．
%While these studies look at the logic of analyzing AUT, they have little focus on how effective these methods actually are in reducing duplication and missing test conditions when working with more than one person.
それらの研究はテスト分析手法の論理に着目をしているけれども，複数の人数でテスト分析を行う際のテスト条件の重複と欠落について，手法を適用すると実際はどの程度効果的であるかについては，大きく着目していない．


%%%%%%%%%%%%%%%%%%%%%%%InSTA2016の論文
\chapter{論理的機能構造を使ったテストケースの特定方法}

%\section{VARIABILITY OF TEST ANALYSIS RESULTS}

\section{テストカテゴリベースドテストのアプローチ}
本章で提案する分析手法は，図~\ref{fig:D-3-Fig3}の論理的機能構造基づいてフィーチャをMECE(互いに相容れなくて完全に徹底的)な方法で分解して，テスト条件を特定する [16]．
図~\ref{fig:D-3-Fig3}に示す各箱が，各フィーチャに要求されるテスト条件を特定する有用なガイドとなる．
\begin{figure}[h]
  \begin{center}
  \includegraphics[width=12cm]{./image/D-3-Fig3.png}
  \caption{MECEにフィーチャからテスト条件を識別する方法}
  \label{fig:D-3-Fig3}
  \end{center}
   \end{figure}

論理構造は抽象的な概念であるため，各個人の解釈に違いが出る可能性がある．テスト条件の特定に一貫性を持たせるため， 論理構造に対してAUTに特化した名前付けを行う．
名前付けしたものをテストカテゴリと呼ぶ．

更に，このテスト分析手法では，テストベースからテスト条件を特定するステップも定義した。

多くのテスト開発に従事するテスト担当者がそのステップに従うと，その全てのテスト担当者は，同じルールに沿って各自の仕事を実行できる． 
結果として，特定したテスト条件の重複や漏れの防止につながる．
これは本手法の主たる効果となる．
更に，この手順には3つの効果がある．
\begin{enumerate}
\item この手順は，本手法で提案しているテスト条件の構造をベースにしている [6]． テストベース内の要素は，仕様項目，期待結果，テストパラメータに分類できる．この手順を通して，各要素は1つずつ順番に特定，選択する． テスト分析にて同じロジックと手順で作成し，同じカテゴリに分類できた各メンバーの最終結果の可読性が向上する．
\item テストカテゴリに対する合意形成によって，チームメンバは仕様項目の特定と選択が容易になる．
\item 本手法は体系化され，標準化され，進めていくのか用意になるため， テスト担当者がテスト分析を繰り返すことができるようになる．
\end{enumerate}

%\section{Remarks from the Verification Experiments検証実験からの考察}
\section{検証実験からの考察}
\subsection{検証実験の手順}
これまでの研究では，同一組織内で本手法を導入したグループと導入していないグループでの仕様項目の選択数を比較する実験を行い効果を確認している[KESの論文].
更にテストカテゴリを使った分析手法の効果を証明するために，複数のグループに対して本手法の習得前と習得後で選択した仕様項目の数を比較する検証実験を行った．
検証実験は，ワークショップを通じて実施した．
ワークショップでは，最初に，演習に使うテストベースを示すが，参加者が各自の考えに基づいたテスト分析を実行してもらう．
その後，ランダムに4〜5名の参加者をランダムにグルーピングし，グループ内で各自のテスト分析の結果をグループの回答としてまとめる．
最初の分析結果のまとめが終わった後、テストカテゴリを用いたテスト分析手法と実施手順をを説明し、その手順に沿って再度テスト分析を参加者が各自で実施し，その後は最初の分析結果同様にグループの回答をまとめる．
ワークショップの一連のアウトプットを検証実験のデータとして利用した.
検証実験は3回実施した．
\subsection{1回目と2回目の検証実験結果の評価}
1回目，2回目の実験では，グループでの回答を実験結果として利用し，8つの実験結果が収集できた．
テストカテゴリを使った手法を知らないで行った演習結果と，テストカテゴリを用いた分析手法の手順にそった演習結果とで比較をした．
実験結果の評価のために，表~\ref{tbl:D-3-tbl4}に示した評価レベルを利用した． 
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[htbp]
  \centering
  \caption{評価レベルの定義}
    \begin{tabular}{|l|p{14.855em}|}
       \hline
    評価レベル & \multicolumn{1}{l|}{比較結果} \\
        \hline
     B    & リストした仕様項目数は増加していない, かつ実験の期待結果よりも少ない.  \\
        \hline
    -     & リストした仕様項目数は増加していない, しかしすでに期待結果と同数である.  \\
        \hline
    A     & リストした仕様項目数は増加している, しかし実験の期待結果よりも少ない.   \\
       \hline
    A+    & リストした仕様項目数は増加している, かつ実験の期待結果に達している. 仕様項目の数は増加していない,.  \\
        \hline
    \end{tabular}%
  \label{tbl:D-3-tbl4}%
\end{table}%

検証実験での評価結果は，表~\ref{tbl:D-3-tbl5}と表~\ref{tbl:D-3-tbl6}に示したとおりである．
これらの評価結果を確認すると分かる通り、テストカテゴリを使った手法を実装した時の結果では、8つのグループ中７つにてテストカテゴリによる効果が確認できた。

% Table generated by Excel2LaTeX from sheet 'テストカテゴリ毎フェリカと日科技連 (掲載用に加工)'
%Fig. 5-1. The evaluation result of the two verification results
\begin{table}[htbp]
  \centering
  \caption{2つの検証実験結果の評価}
 %   \begin{tabular}{|l|l|l|l|l|l|l|}
    \begin{tabular}{|l|l|l|l|l|l|l|||||}
    \hline
    \multicolumn{1}{|c|}{\multirow{2}[4]{*}{Logical
Structure}} & \multicolumn{6}{c|}{Team} \bigstrut\\
\cline{2-7}          & TM1   & TM2   & TM3   & TM4   & TM5   & TM6 & TM7 & TM8 \bigstrut\\
    \hline
    Conv  & B     & A     & B     & B     & B     & B & A     & A\bigstrut\\
    \hline
    Input &       &       &       &       &       &  & A     & B   \bigstrut\\
    \hline
    Output & -     & -     & -     & -     & -     & A+ & A     & A \bigstrut\\
    \hline
    Storage & -     & A+    & -     & A+    & A+    & -& A     & A  \bigstrut\\
    \hline
    Support & B     & B     & B     & B     & B     & B& B     & A \bigstrut[t]\\
    Mngt  & B     & A     & A     & A+    & A     & A+& B     & A \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tbl:D-3-tbl5}%
\end{table}%

%\section{Evaluation of the third verification experiments}
\section{3回目の検証実験の評価}
3回目の検証実験では，各参加者の実施結果を収集し．57名分の実験結果を収集した．
ワークショップのを通して，テスト分析手法を知らない状態での演習実施、一部分だけ説明した状態で演習実施，すべて説明した状態で演習実施、すべて理解した状態で題材を変更して演習実施といったように４回行った．
 %<図7 参加者あたりのテスト条件特定数>
%Fig. 11. Test conditions specified number per participant.
\begin{figure}[h]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-3-Fig10.png}
  \caption{参加者あたりのテスト条件特定数}
  \label{fig:D-3-Fig10}
  \end{center}
   \end{figure}

各参加者が特定できたテスト条件数 (回答数) を図\ref{tbl:D-3-tbl10}の箱ひげ図を用いて比較した．
図\ref{tbl:D-3-tbl10}のY 軸は参加者が回答したテスト条件数を示し，X 軸は，各演習における回答数の分布を箱ひげ図で示している． 1a(テスト分析手法を知らない状態での演習実施) では，最高点は5であり，中央値は1 と非常に低い値であった．
その後、1bでは中央値が3，1c では4，2 では7 と，演習が進むごとに中央値が増えているので， テストカテゴリを使ったテスト分析手法を使うことによって，テスト条件数を特定するスキルが向上したと考えられる．
%今回のワークショップでは， 1a の演習にて，解答をこれまでの経験に基づいて自由に書いてもらうようにした．この結果， テストの記載パターンが4 つに分類できることがわかった．
%%<表3 テスト記述パターン>
%% Table generated by Excel2LaTeX from sheet 'Sheet4'
%\begin{table}[htbp]
%  \centering
%  \caption{テスト記述パターン}
%    \begin{tabular}{|c|p{8.57em}|p{10.215em}|p{3.855em}|}
%    \hline
%          & \textbf{パターン} & \textbf{記載内容} & \multicolumn{1}{c|}{} \bigstrut\\
%    \hline
%    1     & 仕様項目  & 「○○な場合に××なること」といったテスト対象の仕様 & 分析的 \bigstrut\\
%    \hline
%    2     & テストケース & 入力値，アクション，期待結果 & 実装的 \bigstrut\\
%    \hline
%    3     & P-V
%(パラメータ/値） & パラメータと値 & 分析的 \bigstrut[t]\\
%    4     & シナリオ  & 操作手順として記載 & 実装的 \bigstrut[b]\\
%    \hline
%    \end{tabular}%
%  \label{tbl:D-3-tbl11}%
%\end{table}%
%
%表~\ref{tbl:D-3-tbl11}の1 と3 は中間成果物的であり， 記載した内容を見てそのままテストを実行するには不向きである．
%一方，2と4 はそのままテスト実行時に利用できる．
%一方， 分析や設計をすると1 と3 が成果物になる．
%自由に記載してもらう際に分析結果から書くことは，普段の業務でも分析や設計をしていると想定できる．
%なので， 2と4 を直接書くのは， 普段の業務であまり分析や設計行為をしていないのではないかという仮説を持った．
%仮説が正しければ， 普段から業務にて分析や設計をしている参加者のほうが， 慣れているために知識の習得が早いと想定し， 今回のワークショップを通じた演習結果にてこれまでの記載方法と演習の成果に相関があるかを調査した．
%図~\ref{fig:D-3-Fig13} がスピアマンの順序相関分析をした結果である，
%e1a では， 仕様項目から記載する参加者と特定できたテスト条件数には， 0.51(0.4 以上の値は相関ありといえる)の相関が出たたがそれ以外は0.4 以上の値は出なかった． グラフの傾向からは， e2では分析的な記述をしていた参加者のほうが実装的な記述をした参加者より正の相関となったが， 分析結果の値は0.2 をきっているため，相関があるとは結論付けられない．
%\begin{figure}[h]
%  \begin{center}
%  \includegraphics[width=10cm]{./image/D-3-Fig13.png}
%  \caption{e1aの参加者業務分野別テスト条件特定数}
%  \label{fig:D-3-Fig13}
%  \end{center}
%   \end{figure}
%
%%The correlation only participants came out to the specifications items of e1a, the test conditions to be specified in this exercise, because it is a specification item itself, the correlation of the the participants result the specifications items in the first exercise It is considered to have moved out.
%e1a の仕様項目を記載する参加者だけ相関が出たのは，今回の演習で特定するテスト条件が仕様項目そのものであるため， 最初の演習では仕様項目を記載した参加者と結果の相関が出たと考えられる．

\section{終わりに}
３回の検証実験を通じて，本手法の説明を参加者にすることによるテスト条件を特定できる数の向上が観察できた．
%更にI/Oデータパターンを使った実験結果の分析によって，実験結果の一部が本手法で提唱している仮説と一致することを観察できた．
%更に高精度に傾向を分析するため，検証実験は必要である．
以降のこの手法の効果と関連する要因とその傾向に対する深い理解とそのための更なる実験をすることで，AUTとフォールトの知識をベースにしたテストカテゴリを作るためのルールをより洗練できると考えている．

%%%%%%%%%%%%%%%%%%%%%%%InSTA2015の論文
\chapter{I/Oテストデータパターンを使ったテストケースの特定方法}
\section{既出のテスト分析手法の課題}
２章では，一貫性のあるルールを適用することでテストケース作成に必要な仕様項目の特定の際に抜け漏れが少なくなることを確認している．
しかしながら，今までの研究にて提案した手法は，テストベースの分析に論理的機能構造をガイドとして使用することを明示しているだけであり，テスト対象を分析するための具体的な考え方について定義できていない．
そのため，実験の際に被験者に対して，テスト分析にて仕様項目の選択を網羅的に行う具体的な方法を明確に提示できていない．
３章では，テスト実行時のデータのI/O に着目し，
%テスト実行時のデータI/Oのパターンを分析の分類に対する全体集合として定義する．
テストベースを分析する際にテスト実行時のデータI/Oの要素で分解し網羅性を確認する方法を，既存の手法に追加することを提案する．

%\section{An approuch to detarmin spec-item by I/O Test Data Pattarns}
\section{I/Oテストデータパターンを使った仕様項目特定の方法}

\subsection{I/Oテストデータパターン}

テストを実行するためには，データをAUTにインプットし，AUTのアウトプットを期待結果と実際の結果で比較する．
たとえば，シンプルな機能の四則演算の計算結果が正しいことを検証するときには， AUTの外部から複数の値を入力し， AUTがそれらの値を計算し，計算結果をAUTの外部にアウトプットする.これは，図〜ref {fig：D-4-Fig5}で示している例「 Data-in from outside，Data-out to outside，」となる
固定比率が計算結果に適用されるとき(他の計算も適用されると言う意味で)，AUTは適切な比率を呼び出し，利用してから計算結果をアウトプットする．
これは図〜ref {fig：D-4-Fig5}で示している例「Data-in from outside and inside， Data-out to outside」となる
 \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-3-Fig4.png}
  \caption{AUTのデータの入出力の説明}
  \label{fig:D-4-Fig5}
  \end{center}
   \end{figure}


% 注意すべきこととしてI/OデータパターンはAUTの外部からの観察が可能なものを選ぶことがあげられる．処理の起動終了に使われる内部のコマンド（シグナルやイベント）は，データパターンへ分類をするときに考慮しない．なぜならこの手法はブラックボックステストのためのテストベースの分析手法であり，AUT内部のシグナルやイベントのような内部コマンド はブラックボックステストでは，明示的に考慮しないからである．

AUTへのデータの入力の方法は3パターンに分類できる．同じようにAUTからのアウトプット方法は3パターンに集約でき，分類の組み合わせ数はすべてで9パターンとなる.
%そのため，AUTに対するテスト実行時のデータの入出力をまとめたパターンは図〜ref {fig：D-4-Fig6}のように9パターンに集約できる．
%    \begin{figure}[htbp]
%  \begin{center}
%  \includegraphics[width=10cm]{./image/D-3-Fig5.png}
%  \caption{I/Oデータパターンの説明}
%  \label{fig:D-4-Fig6}
%  \end{center}
%   \end{figure}

これをI/Oテストデータパターンと呼ぶ.
I/Oテストデータパターンがテスト実行時のデータの入出力から見た全体集合となる．
%そのため，AUTに対するテスト実行時のデータの入出力をまとめたパターンは図〜ref {fig：D-4-Fig6}のように9パターンに集約できる．
%    \begin{figure}[htbp]
%  \begin{center}
%  \includegraphics[width=10cm]{./image/D-3-Fig5.png}
%  \caption{I/Oデータパターンの説明}
%  \label{fig:D-4-Fig6}
%  \end{center}
%   \end{figure}


%TABLE II. I/O DATA PATTERNS AND THE LOGICAL STRUCTURE OF A FEATURE   \label{tbl:D-4-tbl2}%

たとえば，P1に分類できるシンプルな四則演算の場合，外部からの入力に対して外部に出力する間に，図〜ref {fig：D-4-Fig7}のように論理的機能構造のInput Adjustment，Output Adjustment，Conversionを通過する．そのため，P1はTableIIの3箇所にプロットされている

   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig7.png}
  \caption{Fig. 7. An explanation of the I/O data patterns.}
  \label{fig:D-4-Fig7}
  \end{center}
   \end{figure}

しかし，実際に期待結果を確認するチェックポイントは3箇所とは限らない．なぜなら，入力調整に該当する入力の際に適切な値だけ受け入れることと，変換に該当する計算が適切に行われていることの2つだけであり，出力が適切にされることはチェックポイントとしないといったケースが考えられるためである．
　また，TableIII図〜ref {tbl:D-4-tbl1}では，サポートと相互作用についてはデータパターンがプロットされていない．なぜならP1からP9のI/Oデータパターンは単一の入出力の全体像だからである．

%TABLE III. RESULTS FROM EXPERIMENTS PERFORMED IN PREVIOUS STUDIES

論理的機能構造の要素であるInput Adjustment，Output Adjustment，Conversion，Storageは，外部観察可能な単一の入出力のみを考慮している分類であるのに対して，SupportとInteractionは，単一の入出力だけではなく，関係する他の処理の呼び出しに着目して仕様項目を特定するための分類である．
SupportとInteractionに分類される仕様項目は，呼び出した後の出力で期待結果を確認する. 呼び出された機能のI/Oテストデータパターンは，論理的に全パターンが発生する可能性がある．そこで，これまでの研究で行った被験者を使ってテストカテゴリを使った分析手法の習得前と習得後を比較する実験にて使用したテスト分析の講師解答例を同じフォーマットの表に当てはめて，実際の傾向を調査した

\subsection{これまでの実験データを使った調査}
この実験では，ヘッドセットのフィーチャであるボリュームコントロールと，フライト予約システムのフィーチャである新規フライト予約の2種類の異なったAUTを実験に使用した．実験で解答例として作成したテスト分析結果をI/Oテストデータパターンで整理した結果がTableIIIである．この結果からわかるとおり，実際に現れたパターンは，P1とP2 とP4とP7だけであり，P1からP9のパターンの全てが現れなかった．またP1でプロットされているのはInput AdjustmentとConversionのみであり，Output Adjustmentに該当する仕様項目は無かった．同様にP2はStorageのみ，P4はConversionとOutput Adjustmentのみであり，各I/Oデータパターンのデータのフローの中で期待結果を確認するチェックポイントが限られていることが確認できた．

\subsection{サポートと相互作用に関する考察}
また，TableIIでは，SupportとInteractionに分類できるI/Oテストデータパターンを特定できていなかったが，実際のテスト分析結果から調査した結果，
TableIIIで示したとおり，P1とP2とP4とP7に仕様項目を分類できた
TableIVには，TableIIIと同実験にてSupportとInteractionに分類した仕様項目を列挙した．

SupportとInteractionとして特定して仕様項目の傾向について以下のような考察が出来る

Supportは，テスト対象フィーチャでのテスト実行時のアクションによって内部的に呼び出される別の処理の結果確認のことを指している．この例では，全てテスト対象の入力に対して結果を返すだけであるため，I/OテストデータパターンはP1としている


一方，Interactionは，テスト実行時のアクションによる副作用を，他フィーチャに対するアクションにて呼び出して確認することを指している

この例では，ボリュームコントロールの2つの仕様項目は，副作用を確認する際に，該当する他フィーチャにてテスト実行時に外部から入力を与えて結果を確認するためP1にしている．

フライト予約システムの場合は，新規フライト予約にて登録した新規予約が反映していることを他のフィーチャにて確認することを指しているが，テスト実行の際は該当のフィーチャに対して外部入力を与えずともすでに保存された結果の出力で確認ができるためP4としている.

TableVには，各仕様項目を特定する際のきっかけとなる呼び出し方法を列挙した．サポートに該当する仕様項目の特定に使う呼び出しのきっかけと相互作用に該当する仕様項目の特定に使う呼び出しのきっかけを整理することで，他のAUTに適用する際に活用できると考えられるためである．呼び出しのきっかけとI/O test data patternの組み合わせはTableVのように整理できた．

\section{I/Oテストデータパターンを使ったテスト分析の実験}
これまでの実験では，被験者の学習過程に対する効果を検証してきた．また，AUTは，実験用に作られた小さなサンプルを利用していた．本論文の実験では，現実のプロジェクトで作られたテストケースと，今回提案するI/Oテストデータパターンを使ったテスト分析結果を比較し，手法の効果を分析する

\subsection{実験の目的}
この実験は以下の目的で行う．

\subsubsection{I/Oテストデータパターンの効果実証}
\begin{itemize}
\item 目的：今回提案しているテストカテゴリにI/Oテストデータパターンを使う手法が，現実のテスト設計と比較して網羅的に仕様項目を特定できることを確認する．
\item 評価方法：現実のテスト設計の結果と，I/Oテストデータパターンを使った分析結果を比較する．
\end{itemize}


\subsection{実験の題材について}
実験対象のAUTは，実在するオンラインのモバイル写真共有アプリケーションを使った．
簡単なサンプルでは出現しないI/Oデータパターンもあるため，現実の複雑なアプリケーションを対象にした．
%全機能のうち，「アップロード（デバイス上の写真をオンラインサーバへアップロード）」，「グリッドビュー（オンライン上の写真をデバイスにてサムネイルの一覧として閲覧）」という二つのFeatureをテスト対象として選択した．
%この二つの機能を選択した理由は，データの内部への投入を行う機能とデータの照会のみ行う機能とで，I/Oテストデータパターンの出現傾向が異なること調査することが出来ると考えたためである．

\subsection{実験の実施手順}
モバイル写真共有アプリケーションの開発にて実際に使われたテストケースと、提案する手法で分析した結果を比較する．
実験での実施手順を次に説明する.
%\begin{itemize}
%\item 実際に使われたテストケースを整理してテスト条件にまとめ上げる．
%\item テスト対象フィーチャで使われる入力データ，出力データを明らかにする
%\item I/Oテストデータパターンを付与する
%\item 論理的機能構造とI/Oテストデータパターンを使ってテストベースを分析する
%\end{itemize}
\subsubsection{実際のプロジェクトでのテストケースをテスト条件ごとに整理する}
今回の実験で使う成果物には，テストケースのみであり，テスト分析のアウトプットとなるテスト条件のリストはなかった．
テストケースは，入力値や事前条件を組み合わせた複数のインスタンスであるため，今回の実験のためにテスト分析でのアウトプットとしてまとめなおした．
%図〜ref {fig：D-4-Fig8}のように，テストケースの要素を整理し，同じアクションを行い，同じ期待結果を確認しているテストケースはひとつの仕様項目としてまとめた．
%%Fig. 8. An explanation of summed up a spec-item from test cases.
%   \begin{figure}[htbp]
%  \begin{center}
%  \includegraphics[width=10cm]{./image/D-4-Fig8.png}
%  \caption{テストケースから仕様項目をまとめる方法の説明}
%  \label{fig:D-4-Fig8}
%  \end{center}
%   \end{figure}
現場で作られたテストケースの数は，アップロードが491ケース，グリッドビューが151ケースであった．
整理した結果，アップロードが59項目，グリッドビューが22項目のテスト条件となった．
%このように数量が変わる理由は，たとえば「デバイスからサーバーへ画像ファイルをアップロードして保存が出来ること」というひとつの仕様項目に対して，テストケースは，画像の種類（Jpg，Bmpなど），画像のサイズ，アップロードする画像の枚数，画像情報のパターン（ファイル名，撮影日など）といったテストパラメータを組み合わせたものがテストケースとなっているためである．

\subsubsection{2)テスト対象フィーチャで使われる入力データ，出力データを明らかにする}
テスト対象フィーチャであるアップロードとグリッドビューのテストベースを分析し，画像データ，画像の情報、設定データ，外部コマンドを入力データ，出力データとして扱うこととした.
%\begin{itemize}
% \item 画像データ
% \item 画像の情報
% \item 設定データ
%  \item コマンド
%\end{itemize}

\subsubsection{3)I/Oテストデータパターンを付与する}
特定した入力データと出力データは，2)で明らかにした仕様項目に対して図〜ref {fig：D-4-Fig9}のリストに示す通り，Input data ,Output dataというカラムに追記していった．
テスト実行時の追記したデータの流れをシミュレーションし，該当するI/Oテストデータパターンを明らかにした．
図〜ref {fig：D-4-Fig9}は，ソート順の情報を外部から入力し，内部からの入力となる画像データと一緒になり，外部にソートした画像データを表示している例である．この場合のI/OテストデータパターンはP7となる．
%Fig. 9. An explanation of adding input data and output data to a spec item.
   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig9.png}
  \caption{仕様項目に入力データと出力データを加える方法の説明}
  \label{fig:D-4-Fig9}
  \end{center}
   \end{figure}

\subsubsection{4)論理的機能構造とI/Oテストデータパターンを使ってテストベースを分析する}
I/Oテストデータパターンと既存の分析手法であるテストカテゴリを併用してテスト分析を行った．
%作業ステップは以下のとおりである：
%TableVI，VIIのようにテストカテゴリを特定する
%テストカテゴリ毎に入力データと出力データを明らかにする
%I/Oテストデータパターンごとのデータの流れをシミュレーションして仕様項目を選択する
%現場のテストケースを分析した結果をテストカテゴリに分類し，差異を比較する．
%SupportとInteractionについては，テストカテゴリとして特定したTriggerで呼び出す機能から仕様項目を選択した

\subsection{実験結果の評価}

\subsubsection{1)IOテストデータパターンの効果実証の結果}
テストカテゴリとI/Oテストデータパターンを使ったテストベースの分析を行った結果を図〜ref {fig：D-4-Fig10}に示す．
%今回のテスト対象フィーチャであるUploadとGrandviewの 両方でテストカテゴリとI/Oテストデータパターンを使ったテストベースの分析が適用できた．
%そして，両方のフィーチャにて，現実のAUTに おけるテスト設計と比較し，現場のテスト設計に仕様項目が不足していることが実証できた．
%分類に利用したI/Oテストデータパターンは，P5とP8を除く全てであった．
実プロジェクトの仕様項目との比較をした結果を両者を比較すると，テストカテゴリとI/Oテストデータパターンを利用したテスト分析の結果が実プロジェクトより多くの仕様項目を選択できたことが確認できている．
%Fig. 10. Finding the remainder of each data pattarn between Test-Category and the real project.
   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig10.png}
  \caption{Finding the remainder of each data pattebrn between Test-Category and the real project.}
  \label{fig:D-4-Fig10}
  \end{center}
   \end{figure}

\subsubsection{2)I/Oテストデータパターン毎の出現傾向の評価}

現実のプロジェクトで作られたテストケースとテストカテゴリとI/Oテストデータパターンを使ったテストベースの分析結果をP1からP9の分類で出現割合を比較した結果が，図〜ref {fig：D-4-Fig11}である．
それぞれのI/Oテストデータパターンの選択数の差異を図〜ref {fig：D-4-Fig11}にて確認すると，P1が特にテストカテゴリと実プロジェクトの差異が大きいことがわかる．
P1は外部からの入力を行い，外部に出力する最も単純なパターンであり，単純なパターンの仕様項目がより網羅的に特定できていたことが確認できる．
%Fig. 11. Finding the remainder of each data pattebrn between Test-Category and the real project.
   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig11.png}
  \caption{IOテストデータパターンごとの違い}
  \label{fig:D-4-Fig11}
  \end{center}
   \end{figure}


\subsubsection{3)現実のプロジェクトにて不足していた仕様項目}
%
%図〜ref {fig：D-4-Fig10}には，現実のプロジェクトにて不足していた仕様項目をいくつか抜粋して列挙した．これらの仕様項目は，全て今回のデータのI/Oのシミュレーションを行い網羅的にテストベースを確認することで特定できたものである．

不足していた仕様項目には，論理的機能構造の要素別に見てもInput Adjustment, Output Adjustmentといったメッセージが現れることや入力制御といった単純なことを確認する仕様項目でも漏れているものもあることが確認できる．
一般的に，仕様項目のリストを作成せずにテストケースを作った場合，テストケースのままでは数量の多さから網羅すべき仕様項目の見易さが低下するため，仕様項目の数が不足することが多い．
実験結果も同様の傾向となった．

\section{終わりに}
　本章では，テスト実行時のデータI/Oの要素で分類し網羅的に分析する方法を提案した．そして，現場のテストプロジェクトのテストケースを使い，提案した方法の実証を試みた．結果的に，提案した方法で特定した仕様項目と実プロジェクトで作られるテストケースと比較して，不足している仕様項目の発見が可能であることが確認できた．I/Oテストデータパターンを活用したテスト分析をするためには，まだ多くのサンプルを入手し，全てのI/Oテストデータパターンをナレッジにする必要がある．ナレッジにすることで，テスト分析にて仕様項目を効率よく特定するルールを確立させていきたい．

%\section{謝辞}
%We would like to thank NPO ASTER to use test cases in the real project for the experiment and for allowing us to publish these results.



%%%%%%%%%%%%%%%%%%%%%%%
%電気学会の論文とSSを参考に。現在は変更における状態を含むテスト網羅尺度とテストケース抽出法の提案をコピー
\chapter{データ共有タスク間の順序組合せテストケース抽出手法}

%%%%%%%%%%%%%%%%%%%%%%%
\section{はじめに}
これまでの研究にて、テストカテゴリを使ったブラックボックステストのためのテスト分析手法を提案してきた。
テストカテゴリを使ったテスト分析では、論理的機能構造という参照モデルを使う。
モデルの要素である入力調整，出力調整，変換，貯蔵、サポート、相互作用でテスト対象をカテゴライズしてテスト条件を特定する。
入力調整，出力調整，変換，貯蔵は、外部観察可能な単一の入出力のみを考慮している分類であり，既出の研究て提案したI/O テストデータパターンで網羅することができる。
しかし、サポートと相互作用は，単一の入出力だけではテスト条件の抽出が出来ない。
なぜなら，サポートと相互作用は，単一の入出力だけではなく，関係する他の処理の呼び出しに着目してテスト条件を抽出するための分類であり，統合して確認すべきテスト条件の抽出が必要だからである。
テストケース数の増加は，単一機能のテストより機能間の統合において問題となる。
この場合のテストケース数は，単一の機能や制御構造の和で求めるのではなく，積となるためである。
それに加え，このテストでは，状態遷移に伴う時系列の組合せのテストも求められることから，テストケース数の爆発問題が生じる。
必要なテストケースの抽出方法とその網羅性に関する研究は多々あるが，多くは機能や制御構造を基にした方法である\cite{Myers,Lee,Grinda,Ostrand}。
状態遷移間の組合せについてはNスイッチカバレージに従ってテストケースを抽出する方法がある。
Nスイッチカバレージとは，状態の遷移をパスとし，N+1個の遷移パスを網羅する基準に従て組合せテストケースを作成する。
N=0では遷移パスの組合せをテストできないためN=1，すなわちS1網羅基準（1スイッチカバレージ）が必要とされている\cite{Beizer}。
しかし，S1網羅基準を満たすテストケース数は，２つの状態遷移間における遷移数の積となり，膨大なテスト工数を必要とする課題になる。
本論文では，機能間の統合における状態遷移間の組合せに着目する。

\section{テストケース抽出方法と課題}
S1 網羅基準の課題に対す るアプローチとしては,テストケース数を削減する研究と, 自動化により工数を削減する先行研究がある。
自動化による工数削減の研究は,N-スイッチカバレージ を満たすテストケースを形式仕様から自動生成する方法が 知られている。
この方法は,テスト対象となる IT システム の動作を正確に記述したモデルを定義し,そのモデルから 特定の長さの連続した遷移を抽出する方法である (14) 。
対象システムが運動方程式などに従う一般的なモデルベー ステストと異なり,状態遷移にて生ずるシステムの動的な 振舞いを形式仕様化する必要があり,それが困難であるこ とから一般的な IT システムで適用された例は見当たらない。
生成されるテストケース数は N-スイッチカバレージと 同じであり削減されないので,テストケースが自動抽出さ れても,実行のための操作は人手に頼る部分が残り,作業 工数を合理化できない課題がある。
テストケース数を削減する研究としては,状態遷移の組 合せに対して直交表を応用し2因子間の組合せを中心に, 一部3因子の組合せも抽出する研究がある (15) (16) 。
この方法 は,決定表を用いて機械的に組合せを抽出でき,2 因子間 の組合せ即ち S0 網羅基準は完全に網羅できるが,S1 網羅 基準の網羅は不完全であり,かつその選択基準が用いた直 交表に左右されるため重要なテストケースが漏れる課題が ある。
 本研究は,テストケース数を削減するアプローチに属する。
テストケースを機械的に削減するのでは無く,実践の場における経験から生じるノウハウを用いて削減する。
状態遷移に係る不具合は,定義された状態変数や画面とは別に,内部に保存されたデータが影響していることが知られ ている。
具体的には,状態の制御が状態変数や画面によっ て一意に動作するように設計されていたとしても,内部変 数で保持されたデータが存在すると,これが隠れたサブ状 態となり,設計とは異なる振舞いが生じ不具合となる。
本論文では,このような不具合を見つけ出すために必要なテ ストケースを,DFD,ER 図,CRUD 図といったデータ設計文書を入力情報として使うことで合理的に抽出する方法を提案する。

\section{順序組合せによるテストケース抽出法}
本論文では,状態遷移テスト設計における「S1 網羅基準 ではテストケース数が爆発するが,S0 網羅基準では漏れが 生じる」という課題を解決する手法として順序組合せテス トを提案する。

\subsection{順序組合せテストの概要}
提案する手法は，2タスク間の順序組合せを対象とする．
%データストアを共有しないタスク間の組合せは, マルコフ連鎖を前提として順序組合せテストの対象から除外する．
%データストアを共有していないため，画面遷移あるいは状態遷移は独立しており，S0網羅基準にてテストを行えば十分だと考えられるからである．
2タスク間の順序組合せの抽出は以下のルールを適用する．

\subsection{ルール1：変更タスクの特定}
ルール１を用いて変更タスクとそのデータストアを特定し，拡張CRUD図の変更タスク部分を作成する．

拡張CRUD図とは，テストベースとして与えられたDFD，ER図，CRUD図から$P\{Ta\}$の各$Ta_i$と関連する$So_k$，そして$P\{Ds\}$となる$Ds_j$の関係を追加して作成したものである．


\subsection{ルール2：波及タスクの特定}
ルール2を用いて波及タスク群を特定し，拡張CRUD図へ波及タスク部分を追加し図を完成させる．

先に作成した中間の拡張図から変更タスクの操作が$C$か$U$か$D$であるデータストアに着目する．
着目したデータストアに対してエッジを持つタスクが波及タスクのうち，源泉に出力エッジを持つタスクを波及タスクとして特定する．
特定した波及タスクを拡張CRUD図に追記し完成させる．

完成させた拡張CRUD図の例を表~\ref{excrud}に示す．
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[t]
  \centering
  \caption{完成した拡張CRUD図の例}
    \begin{tabular}{r|r|r|r|r|r|r}
    \multicolumn{1}{c|}{タスク} & \multicolumn{3}{c|}{データストア} & \multicolumn{3}{c}{源泉} \\
\cline{2-7}    \multicolumn{1}{c|}{} & $Ds_1$ & $Ds_2$ & $Ds_3$ & $So_1$ & $So_2$ & $So_3$ \\
    \hline
    \hline
    $Ta_1[St_1]$ & $CU$ &   &   & $In$ &   &  \\
    \hline
    $Ta_3[St_1]$ &   & $C$ &   & $In$ &   &  \\
    \hline
    $Ta_2[St_1]$ & $R$ &   &   &   & $Out$ &  \\
    \hline
    $Ta_5[St_1]$ &   & $R$U &   &   &   & $Out$ \\
    \end{tabular}%
  \label{excrud}%
\end{table}%

\subsection{ルール3：順序組合せテストケースの抽出}
拡張CRUD図を基に順序組合せのテストケースを抽出し，テストケース表を作成する．
表 ~\ref{TCLISTSAMPLE}にその例を示す．概要の部分は，当該組合せが持つ入力の条件や出力の特性を仕様から抜き出して記載する．

%--------------------------------

\end{enumerate}

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[t]
  \centering
  \caption{順序組合せテストによる論理的テストケースの例}
    \begin{tabular}{l|l|l}
    No & 論理的テストケース & 順序組合せ \\
    \hline
    1 & 概要 & $Ta_1C \rightarrow Ta_2R$ \\
    \hline
    2 & 概要 & $Ta_1U \rightarrow Ta_2R$ \\
    \hline
    3 & 概要 & $Ta_3C \rightarrow Ta_2R$ \\
    \hline
    4 & 概要 & $Ta_3C \rightarrow Ta_2U$ \\
    \hline
    \end{tabular}%
\label{TCLISTSAMPLE}
\end{table}%


以上の手順で，順序組合せテストに必要なテストケースを抽出する．

\section{順序組合せテストの適用評価}
本節では，旅行代理店向けフライト予約システムの仕様を用いて，3章で述べた実施手順を適用し，順序組合せが抽出できることを確認する．
%本論文では，表~\ref{Featurelist}の新規フライト予約を，変更が入った機能セットとする．
%新規フライト予約からテストケースを抽出するための前提として用意した仕様は，新規フライト予約に関連するDFDとER図（図~\ref{fig:DFD}），CRUD図（表~\ref{CRUD}）とする．
%%DFDに含まれるタスク数 $N$は6，データストア数$M$は2，源泉数$L$は4である．


%\subsection{ルール1：変更タスクの特定}
%テストベースであるDFDに含まれるタスク数$N$は6であるが，変更が入った新規フライト予約の変更タスクは，表~\ref{CRUD}のCRUD図を確認するとフライト検索$Ta_1$とフライト予約$Ta_2$であることがわかる．
%図~\ref{fig:DFD}から，$Ta_1$と$Ta_2$の外部入力を確認する．
%$Ta_1$は，Customer$So_1$からETDとDestinationを外部入力し，$Ta_2$は，Customer$So_1$からFlightNo，Cl$AS$s，Order number，PAXを外部入力している．
%
%続いて，$Ta_1$と$Ta_2$の内部出力を確認する．
%$Ta_1$はFlight info$Ds_1$に対して検索条件を与えているのみで内部入力はしていないため，変更タスク群$P\{Ta\}$からは除外する．
%$Ta_2$がFlight info$Ds_1$で$U$，Booking info$Ds_2$で$C$を行っていることが表~\ref{CRUD}から読み取れる．
%これらから，拡張CRUD図（表~\ref{ECRUD1}）を作る．
%表~\ref{ECRUD1}から，ルール１に適合する$Ta_2/Ds_1U$，$Ta_2/Ds_2C$を特定できる．
%
%\begin{table}[t]
%\caption{フライト予約システムの中間拡張CRUD図}
%\label{ECRUD1}
%\begin{center}
%\begin{tabular}{c||c|c||c|c|c|c}
%\hline
%タスク&\multicolumn{2}{c||}{データストア}&\multicolumn{4}{c}{源泉}\\
%&$Ds_1$&$Ds_2$&$So_1$&$So_2$&$So_3$&$So_4$\\
%\hline\hline
%$Ta_1$&&&&&&\\
%\hline
%$Ta_2$&$U$&$C$&$In$&&&\\
%\hline
%\end{tabular}
%%\halflineskip
%\end{center}
%\end{table}%


%\subsection{ルール2：波及タスクの特定}
%ルール2にて波及タスク群$S\{Ta\}$を抽出するために，タスクの外部出力を図~\ref{fig:DFD}のDFDから調べる．
%$P\{Ds\}$に含まれる$Ds_1$と$Ds_2$とエッジを持ち，かつ$So$へ出力するタスク群が$S\{Ta\}$候補である．
%図~\ref{fig:DFD}では，全てのタスクが$Ds_1$および$Ds_2$からのエッジを持つ．
%しかし，$So$への出力に着目すると，$Ta_4$は該当するエッジがないため，$S\{Ta\}$候補には入らない．
%
%$S\{Ta\}$候補のうち、表~\ref{table:3}の○がつく組合せに相当する$Ta_i$が，ルール2で特定したタスクとなる．
%本章の例の場合，$P\{Ta\}$での操作は，$C$と$U$であるため，$S\{Ta\}$候補の中で$C$の操作をする$Ta_i$以外は全てルール2で特定したタスクとなる．
%
%これらに該当する$Ta_i$と$Ds$へのCRUD操作，そして$So$への$Out$を追記し，表~\ref{ECRUD2}を完成させる．
%
%\begin{table}[t]
%\caption{フライト予約システムの拡張CRUD図}
%\label{ECRUD2}
%\begin{center}
%\begin{tabular}{c||c|c||c|c|c|c}
%\hline
%タスク&\multicolumn{2}{c||}{データストア}&\multicolumn{4}{c}{源泉}\\
%&$Ds_1$&$Ds_2$&$So_1$&$So_2$&$So_3$&$So_4$\\
%\hline\hline
%$Ta_1$&$R$&&$Out$&&&\\
%\hline
%$Ta_2$&$RU$&$C$&$InOut$&&&\\
%\hline
%$Ta_3$&&$R$&&&$Out$&\\
%\hline
%$Ta_5$&&$R$&&$Out$&&\\
%\hline
%$Ta_6$&$CU$&&&&&$Out$\\
%\hline
%\end{tabular}
%%\halflineskip
%\end{center}　
%\end{table}%
%\subsection{ルール3：手順 順序組合せテストケースの抽出}
%表~\ref{ECRUD2}の拡張 CRUD 図から変更タスクと波及タスクの組合せを抽出する．
%抽出した変更タスクと波及タスクの組合せに対して，データストアに対する操作を明記したものは以下のとおりとなる．
%\begin{itemize}
%\item $Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_1R$\\
%\item $Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_2/Ds_1U$\\
%\item $Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_6U$\\
%\item $Ta_2/Ds_2C  \xrightarrow[Ds_2]{} Ta_3R$\\
%\item $Ta_2/Ds_2C  \xrightarrow[Ds_2]{} Ta_5R$\\
%\end{itemize}
%これらの変更タスクと波及タスクの操作の順序組合せがテストケースとなる．
%抽出した順序組合せが持つ入力の条件や出力の特性を仕様から抜き出して論理的テストケースとしてまとめる．
%表~\ref{TCLIST2}に論理的テストケースとしてまとめた結果を示す．
%\begin{table}[h]
%\footnotesize
%\caption{順序組合せテストによる論理的テストケース}
%\label{TCLIST2}
%\begin{center}
%%\begin{tabular}{c|p{1 cm}|p{3.5 cm}|p{1.5 cm}}
%\begin{tabular}{c|p{3 cm}|p{2.1 cm}}
%\multicolumn{3}{l}{新規フライト予約}\\
%\hline
%No&論理的テストケース&順序組合せ\\
%\hline\hline
%1&フライト予約後の空き情報問合せによる同一フライトの参照&$Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_1R$\\
%\hline
%2&フライト予約後の再度同一フライトの予約&$Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_2/Ds_1U$\\
%\hline
%3&フライト予約後の同期処理によって最新のチケット残数の計算&$Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_6U$\\
%\hline
%4&既存注文開く画面での予約したフライトの参照&$Ta_2/Ds_2C  \xrightarrow[Ds_2]{} Ta_3R$\\
%\hline
%5&注文件数グラフ・注文履歴の一覧への新規予約フライト予約の反映&$Ta_2/Ds_2C  \xrightarrow[Ds_2]{} Ta_5R$\\
%\hline
%\end{tabular}
%%\halflineskip
%\end{center}
%\end{table}

\section{考察}
%本論文での提案手法は，4章で提示した具体例であるフライト予約システムのDFD，ER図，CRUD図にて，提案したルールに沿ってデータを介したタスク間の順序組合せを抽出できることが確認できた．

%\begin{figure}[h]
%\begin{center}
%\includegraphics[scale=0.3]{screentransition.eps}
%\end{center}
%\caption{フライト予約システムの画面遷移図（一部分）}
%\label{fig:STD}
%\end{figure}


次に提案手法で抽出したタスク間の順序組合せと既出の状態を含む$AP$のテストケースを設計する手法である状態遷移テストで,抽出されるテストケースの比較を行う.状態遷移テストのテストベースとなるフライト予約システムの画面遷移図
%である図~\ref{fig:STD}
を使って,順序組合せが確認できる網羅基準であるS1網羅基準を適用する．
%図~\ref{fig:STD}は，
適用範囲を合わせるために，4章の適用のためのサブセットである新規フライト予約を行うために必要な画面と隣接する画面遷移に該当する範囲の図となっている．
仕様の詳細度合いは，DFD，ER図，CRUD図と画面遷移図では同等にしている．
%それは，画面遷移のイベントでのガード条件に記載したデータがDFDのエッジに記載したデータ，ER図のエンティティの属性と一致していることから確認できる．
S1網羅基準を適用すると28の状態遷移パスとなる．
%この表の提案手法の列には，提案手法で抽出した順序組合せに該当する順序組合せを示した．
%状態遷移パスに対応する提案手法で抽出した順序組合せは28のうち,表~\ref{TCLIST2}テストケースNo.1，2，4，5の4つであった．3-25対応
28の状態遷移パスのうち，対応する提案手法で抽出した順序組合せは，
%表~\ref{TCLIST2}テストケースNo.1，2，4，5の
4つであった．
これらは,本状態遷移図のフライト予約状態での登録イベントを起点にするもののみであった．
順序組合せに該当しない状態遷移パスは，互いのタスクで同一のデータを介して処理をするといったことがない．
例えば，フライト検索をした後にキャンセルをするとフライト予約画面に遷移するパスは，前の処理の結果によって影響を及ぼさない．

S1網羅基準では抽出できないが，本手法によって抽出できたテストケースは，
%No.3の$Ta_2/Ds_1U  \xrightarrow[Ds_1]{} Ta_6U$である．
%このテストケースは，必要なテストケースと考えられる．
%4節の適用評価にて利用したテストベースは，変更が入った機能セットに焦点を絞ったものである．
%4節では新規フライト予約が該当する。そのため，図5では，新規フライト予約に隣接する画面遷移が，該当するテストベースとなっている．
%表~\ref{TCLIST2}のテストケースNo3における波及タスクである$Ta_6U$は，表~\ref{CRUD}から同期処理のタスクであることがわかるが，新規フライト予約とは別の機能セットに含まれるタスクであり，フライト予約画面と隣接する画面遷移図には現れない．
%そのため，S1網羅基準では抽出することができない．
別の機能セットに含まれるタスクであるため，画面遷移図の網羅では現れない.
%提案手法で検出できた理由は，テストベースであるDFD，ER図，CRUD図では，新規フライト予約と同期処理の間にはデータを介した順序組合せがあることを示しているためである．

\section{おわりに}

%本論文では，状態遷移を持つソフトウェアにおいて，変更による変更波及がデータベースや外部変数などの保持データを介して生ずる場合のテストに関して，その網羅基準と，テストケースを抽出する手法を提案した．3-6対応によって修正
本論文では，状態遷移を持つソフトウェアにおいて，変更による変更波及がデータベースや外部変数などの保持データを介して生ずる場合のテストに関して，その網羅基準と,順序組合せテストケースを抽出する手法としてIDAU法を提案した．
DFD，ER図、CRUD図をテストベースとして，3つのルールを適用することでテストが必要な順序組合せを抽出できることを説明した．
提案した手法で組合せが抽出できることを確認するため，フライト予約システムの仕様を具体例にして適用を行った．
最後に従来手法である画面遷移図からS1網羅基準にて抽出した状態遷移パスと提案手法を比較して，テストケース数の削減ができる効果と，S1レベルの画面遷移の網羅では抽出できないテストケースが抽出できる効果を示した．

提案手法に対する今後の取り組みは2つある．
1つは,適用範囲の明確化である.変更のパターン（タスク内の制御ロジックの変更,新しい要素の追加など）に対して,どこまで適用でき,どこからは適用できないかを明らかにする.

もう1つは，今回の提案手法のツール化である．
実際の開発プロジェクトで扱う規模の大きいデータ設計文書に対して本手法を適用する際には，本手法のルールをツール化するといった方法での適用が必要になる．
これらの準備を行い，実践の場に本手法を適用していく．

%%%%%%%%%%%%%%%%%%%%%%%
\chapter{結論}

%%%%%%%%%%%%%%%%%%%%%%%

%\chapter*{謝辞}
%\addcontentsline{toc}{chapter}{\numberline{}謝辞}
%入力例


\newpage

\addcontentsline{toc}{chapter}{\numberline{}参考文献}
\renewcommand{\bibname}{参考文献}

 \bibliographystyle{sieicej}
\bibliography{mybib1}

\end{document}


