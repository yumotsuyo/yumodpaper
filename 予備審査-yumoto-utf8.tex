%\documentclass[12pt,a4j]{jreport}
% \documentclass[a4paper,12pt]{jreport} デフォルト値
\documentclass[a4paper,10pt]{jreport}
%\usepackage[dvips]{graphicx,color}
%\usepackage{array}main
%\usepackage{amsmath,amsthm,amssymb}
%\usepackage{refcheck}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{eepic,eepicsup}
\setlength{\columnsep}{4mm}
\setlength{\parskip}{1.4mm}

\usepackage[dvipdfmx]{graphicx}
\usepackage{url}

\usepackage[fleqn]{amsmath}

\usepackage{caption}
\usepackage{flushend}

%excel2latex用に追加
\usepackage{multirow}
\usepackage{bigstrut}


%筑波大学のフォーマットからコピー
\usepackage{times} % use Times Font instead of Computer Modern

\setcounter{tocdepth}{3}
\setcounter{page}{-1}

\setlength{\oddsidemargin}{0.1in}
\setlength{\evensidemargin}{0.1in}
\setlength{\topmargin}{0in}
\setlength{\textwidth}{6in}
%\setlength{\textheight}{10.1in}
\setlength{\parskip}{0em}
\setlength{\topsep}{0em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% タイトル生成用パッケージ(重要)
%\usepackage{sie-jp-sjis}
\usepackage{sie-jp-utf}

%% タイトル
%% A study on the method of blackbox testing based on I/O data sequence
\title{入出力データの順序情報に基づくブラックボックステスト手法に関する研究}
%% 著者
\author{湯本剛}
%% 学位 (2012/11 追加)
%\degree{}
%% 指導教員
%\advisor{}

%% 専攻名 と 年月
%% 年月は必要に応じて書き替えてください。
%\majorfield{△△△△}\programfield{□□□□}
\yearandmonth{2018年1月}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle
\thispagestyle{empty}

\newpage
% \thispagestyle{empty}
% \vspace*{20pt plus 1fil}
% \parindent=1zw
% \noindent
%%
%% 論文の概要(Abstract)
%%%
%\begin{center}
%{\bf 概要}
本研究はブラックボックステストのテストケース抽出に抜け漏れやケース数が増 大する課題に対して，テスト対象に対する入出力データの順序情報に基づいてテストケースを抽出する 手法を提案し，合理的に
テストケースを抽出することを成果とするものである
%\vspace{5mm}
%\end{center}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\par
\vspace{0pt plus 1fil}
\newpage

\pagenumbering{roman} % I, II, III, IV
\tableofcontents
\listoffigures
\listoftables

\pagebreak \setcounter{page}{1}
\pagenumbering{arabic} % 1,2,3

%%%%%%%%%%%%%%%%%%%%%%%
\section{諸論} % \ label {chap:1}
ソフトウェア開発の中の品質を確保する主要な技術として,ソフトウェアテストがある．
求められるテストケースの数は，昨今のソフトウェアの複雑性と規模の急激な増加に伴い増加の一途をたどっている．
ブラックボックステストの場合，ソフトウェアの規模とテストケース数の関係は，ファンクションポイント総計値の1.15乗から1.3乗となる\cite{jones1998estimating}．また，開発プロジェクトのファンクションポイント総計値は1970年から2000年までの30年間で約10倍の増加を示している\cite{longstreet2000}．

日本におけるテスト工数の割合は開発工数全体の28パーセントから35パーセントを占めるケースが多いが，90パーセントを超えるケースもあるという調査結果が出ている\cite{IPA2015}
また，テストケースを作成する工数は，平均的にテスト工数全体の40パーセントだと言われている\cite{van2013tpi}．
これは，テストケースの開発に多くの人員が必要となることを示している．
多数の人員がテストケースを作成する工程に必要とされているにもかかわらず， テストケースを作成するための明確に定義されたルールがないために，投入された人員は個々の考え方に基づいてテストを開発することが多い．
これはテストケースの重複や漏れの原因となり，テストの活動がソフトウェアの品質を確保する役割を果たせないばかりか，コスト増や納期遅延の原因となる．
本研究では，テストケースを作成する工程に投入される人員が、必要なテストケースを網羅的に抽出し，抜け漏れを防止できるようにすることを目的とし，適切な数のテストケースを開発するための手法を提案し，その適用評価を行う．

本論文は6章で構成される.
2章では，システムテストにおけるブラックボックステストにおける課題と，関連する先行研究について述べる．また，本研究で使用するテスト分析手法について解説する．
3章では，前章で述べた課題を更に分析するために，実験を行い実験結果で確認を行った．
4章では，テストデータの入出力に着目し、テスト対象の分析を網羅的に行う手法の提案と適用評価を行った．
5章では，テストデータの入出力を順番に組み合わせる必要がある際に，重要な順序組み合わせを抽出してテストケースにする方法の提案と適用評価を行なった．
最後の6章では，結論を述べる．
%%%%%%%%%%%%%%%%%%%%%%%
\section{ブラックボックステストにおけるテスト分析とその課題}\label{chap:2}
\subsection{本研究の対象となるテストケースの開発方法とテストレベル}
\subsubsection{テストケースの開発方法}
テストケースを開発する方法は，ソフトウェアの構造を基にテスト設計するホワイトボックステストと，ソフトウェアの仕様を基にテスト設計するブラックボックステストに大別できる\cite{myers2011art} ．
本研究では，ブラックボックステストを対象とする．
%ホワイトボックステストはテスト設計のベースがソースコードのようなテスト対象そのものとなるため，テスト対象プログラムの行を網羅，分岐を網羅といった具合にテストにて網羅すべきアイテムを明確に選択することが容易である．
%網羅基準はテスト設計技法として提唱されている\cite{myers2011art}．
ブラックボックステストは，テスト対象そのものではなく，テスト対象の動作条件や振る舞いについて記述した仕様をベースにしてテストケースを開発する．
%ブラックボックステストのテスト設計技法の中で、仕様に対する網羅基準は，ホワイトボックステスト同様数多く提唱されている\cite{myers2011art}．
ブラックボックステストは，テストベースがAUTの物理的な構造ではなく論理的なふるまいの記述であるがゆえに，テストを作るための詳細化が複数の解釈で行われることが多い\cite{yumoto2013test}．
%%しかし，ブラックボックステストのためのテスト分析は詳細化に一貫性がないことが多く，それがゆえにテストケースの漏れや重複が起きることも多い．本提案では，テスト対象とフォールトを知識化したテストカテゴリを用いて一貫性のあるテスト分析手法を提案する．
%%結果的にテストケースの重複や抜け漏れを引き起こす可能性も高くなる．
%本研究では，ブラックボックステストを対象とする．
\subsubsection{テストレベル}
ソフトウェアテストは，開発ライフサイクルの中で複数のテストレベルに分けて行われる．
%複数のテストレベルは，図~\ref{fig:D-2-Fig1}で示すVモデルと呼ばれる技術面にフォーカスしたサイクルモデルにて表現することができる\cite{arnold1996software}．
各テストレベルはソフトウェア開発の段階的詳細化のレベルと対応している．
本研究は，複数のレベルの中で，システムレベルで行われるブラックボックステストに焦点を当てている．
システムレベルのテストは，開発した単体のソフトウェアがすべて統合されるため，規模の増大と複雑性の増加の影響を直接的に受けるからである．
%\begin{figure}[h]
%  \begin{center}
%   \includegraphics[width=12cm]{./image/D-2-Fig1.png}
%   \caption{Vモデル}
%   \label{fig:D-2-Fig1}
%  \end{center}
%\end{figure}

\subsection{テスト分析}
Vモデルであらわす各レベルにて行われるテストはそれぞれ，開発プロセスと類似したプロセスを持っている [4].
%テストのプロセスは, 図~\ref{fig:D-2-Fig2}のようにテスト計画がVモデルの左側の活動と並行に行われ，その後時系列にテスト分析，テスト設計，テスト実装が行われた後，Vモデルの右側の活動の中で，テスト実行と終了基準の評価が行われる．
テストのプロセスの中でテスト分析，テスト設計，テスト実装の3つの活動はテスト開発プロセスと呼ばれている[5] ．
テスト設計の前には，テスト設計技法が適用できるサイズにテスト対象を詳細化することが必要となる．
この活動はテスト分析と呼ばれている．
% ブラックボックステストを設計するベースとなる仕様とは，図1で示したVモデルの左側の成果物のことである．
% 各検証のレベルでテスト設計のベースする仕様はテストベースと呼ばれている[5]．
% 本提案の対象となるV字モデルのレベルでは図2のsystem performance specificationがテストベースとなる．
% テストベースとなる仕様書は，その後の工程である設計やコーディングといった活動のために記載されるものであるため，テスト設計技法を適用する1つのアイテムに対する仕様が複数個所に分散して記載されてしまうことが多い．
% また，記述が自然言語であることも多く，条件の組み合わせや順序についての記述が不足していることも多い．
% テスト分析はこのようなテストベースに対して，何らかの考え方に基づき，テストにて網羅すべきアイテムを選択し，整理する活動である．
テスト分析は，図~\ref{fig:D-2-Fig2}で示すとおり，テスト開発プロセス中の最初の活動である．
\begin{figure}[h]
  \begin{center}
   \includegraphics[width=8cm]{./image/D-2-Fig2.png}
   \caption{テストプロセスとテスト開発プロセス}
   \label{fig:D-2-Fig2}
  \end{center}
\end{figure}

\subsubsection{テスト分析の課題}
テスト分析の活動の出力となるテスト条件は，機能，トランザクション，品質特性，構造的要素といった多くの側面の総称であるため，各側面の関係を整理するための構造化が必要である．
しかし，テスト分析におけるテスト条件群の構造化は，研究や実務においても，経験則や個人の考え方に基づく構造化に留まっている [6]．
%一般的には，テストベースを表1のように大項目，中項目，小項目と詳細化していくことが多い．
%この方法は，詳細化する際の各分類項目に明確なルールが定義されていないため，個人毎の何かしらの考え方で詳細化するための分類を決めていくことになる．
そのため，分類にばらつきが発生し，同じテスト条件が複数の階層に現れてしまったり，同じ意味のテスト条件が別の名称で選択されるといった混乱が起きてしまう．
したがって，テスト分析が多くの人たちで行われるときには，テスト条件の重複，もしくは完全に抜け落ちるといった可能性が非常に高くなる．
テスト開発の最初の活動であるテスト分析にて特定するテスト条件にこのような問題があるとその後の活動で作られるテストケースの抜け漏れ，重複に大きく影響を及ぼす．

\subsubsection{ブラックボックステストにおけるテスト分析の先行研究}
ISTQBでは，テスト分析を実行するための要求事項や必要性は述べているけれども，テストベースを分析していくためのアプローチは定義されていない．
%これは，Ostrand [8]， Grindal [9]などのテスト開発に関する先行研究でも同様である．
G.J.MyersやB.Beizerといったテストケースを作る技術の先行研究は，テスト分析にてテスト条件が特定された後に適用されるテストパラメータの設計に焦点を当てている．
そのため，テスト条件は，すでに全て準備されたと言う前提になっている.
%Some studies on the test analysis method have also been proposed by Nishi [12], Akiyama [13], etc.
テスト分析手法に関する研究は，Nishi [12]， Akiyama[13]があるが，複数の人数でテスト分析を行う際のテスト条件の重複と欠落について，手法を適用すると実際はどの程度効果的であるかについては，大きく着目していない．


%%%%%%%%%%%%%%%%%%%%%%%InSTA2016の論文%\chapter{論理的機能構造を使ったテストケースの特定方法}
\section{論理的機能構造を使ったテストケースの特定方法}\label{chap:3}
\subsection{テストカテゴリベースドテストのアプローチ}
本章で提案する分析手法は，図~\ref{fig:D-3-Fig3}の論理的機能構造基づいてフィーチャをMECE(互いに相容れなくて完全に徹底的)な方法で分解して，テスト条件を特定する [16]．
図~\ref{fig:D-3-Fig3}に示す各箱が，各フィーチャに要求されるテスト条件を特定する有用なガイドとなる．

\begin{figure}[h]
  \begin{center}
  \includegraphics[width=8cm]{./image/D-3-Fig3.png}
  \caption{MECEにフィーチャからテスト条件を識別する方法}
  \label{fig:D-3-Fig3}
  \end{center}
   \end{figure}

論理構造は抽象的な概念であるため，各個人の解釈に違いが出る可能性がある．テスト条件の特定に一貫性を持たせるため， 論理構造に対してAUTに特化した名前付けを行う．
名前付けしたものをテストカテゴリと呼ぶ．
更に，このテスト分析手法では，テストベースからテスト条件を特定するステップも定義した。
多くのテスト開発に従事するテスト担当者がそのステップに従うと，その全てのテスト担当者は，同じルールに沿って各自の仕事を実行できる．
結果として，特定したテスト条件の重複や漏れの防止につながる．
これは本手法の主たる効果となる．
\subsection{検証実験からの考察}
\subsubsection{検証実験の手順}
テストカテゴリを使った分析手法の効果を証明するために，複数のグループに対して本手法の習得前と習得後で選択した仕様項目の数を比較する検証実験を行った．
検証実験は，ワークショップを通じて実施した．

ワークショップでは，最初に，演習に使うテストベースを示すが，参加者が各自の考えに基づいたテスト分析を実行してもらう．
その後，4〜5名の参加者をランダムにグルーピングし，グループ内で各自のテスト分析の結果をグループの回答としてまとめる．

最初の分析結果のまとめが終わった後、テストカテゴリを用いたテスト分析手法と実施手順をを説明し、その手順に沿って再度テスト分析を参加者が各自で実施し，その後は最初の分析結果同様にグループの回答をまとめる．
ワークショップの一連のアウトプットを検証実験のデータとして利用した.
\subsubsection{1回目と2回目の検証実験結果の評価}
1回目，2回目の実験では，グループでの回答を実験結果として利用し，8つの実験結果が収集できた．
テストカテゴリを使った手法を知らないで行った演習結果と，テストカテゴリを用いた分析手法の手順にそった演習結果とで比較をした．
実験結果の評価のために，A,A-,-,B,N/Aという５段階の評価レベルを利用すします。
表~\ref{tbl:D-3-tbl4}に示した評価レベルを利用した．
検証実験での評価結果は，表~\ref{tbl:D-3-tbl5}に示したとおりである．

これらの評価結果を確認すると分かる通り、テストカテゴリを使った手法を実装した時の結果では、8つのグループ中７つにてテストカテゴリによる効果が確認できた。

\begin{table}[htbp]
\footnotesize
  \centering
  \caption{2つの検証実験結果の評価}
    \begin{tabular}{|l|l|l|l|l|l|l|l|l|}
    \hline
    \multicolumn{1}{|c|}{\multirow{2}[4]{*}{Logical
Structure}} & \multicolumn{8}{c|}{Team} \bigstrut\\
\cline{2-9}          & TM1   & TM2   & TM3   & TM4   & TM5   & TM6 & TM7 & TM8 \bigstrut\\
    \hline
    Conv  & B     & A     & B     & B     & B     & B & A     & A\bigstrut\\
    \hline
    Input &  n/a     &   n/a    &   n/a    &   n/a    &   n/a    &  & A     & B   \bigstrut\\
    \hline
    Output & -     & -     & -     & -     & -     & A+ & A     & A \bigstrut\\
    \hline
    Storage & -     & A+    & -     & A+    & A+    & -& A     & A  \bigstrut\\
    \hline
    Support & B     & B     & B     & B     & B     & B& B     & A \bigstrut[t]\\
    Mngt  & B     & A     & A     & A+    & A     & A+& B     & A \bigstrut[b]\\
    \hline
    \end{tabular}%
  \label{tbl:D-3-tbl5}%
\end{table}%

\subsection{3回目の検証実験の評価}
3回目の検証実験では，各参加者の実施結果を収集し．57名分の実験結果を収集した．
ワークショップのを通して，テスト分析手法を知らない状態での演習実施、一部分だけ説明した状態で演習実施，すべて説明した状態で演習実施、すべて理解した状態で題材を変更して演習実施といったように４回行った．
\begin{figure}[h]
  \begin{center}
  \includegraphics[width=7cm]{./image/D-3-Fig10.png}
  \caption{参加者あたりのテスト条件特定数}
  \label{fig:D-3-Fig10}
  \end{center}
\end{figure}

各参加者が特定できたテスト条件数 (回答数) を図\ref{fig:D-3-Fig10}の箱ひげ図を用いて比較した．
図\ref{fig:D-3-Fig10}のY 軸は参加者が回答したテスト条件数を示し，X 軸は，各演習における回答数の分布を箱ひげ図で示している． 1a(テスト分析手法を知らない状態での演習実施) では，最高点は5であり，中央値は1 と非常に低い値であった．
その後、1bでは中央値が3，1c では4，2 では7 と，演習が進むごとに中央値が増えているので， テストカテゴリを使ったテスト分析手法を使うことによって，テスト条件数を特定するスキルが向上したと考えられる．
\section{終わりに}
３回の検証実験を通じて，本手法の説明を参加者にすることによるテスト条件を特定できる数の向上が観察できた．
以降では，テスト条件を網羅的に特定する方法を提案し，このテスト分析手法の更に洗練させる．

%%%%%%%%%%%%%%%%%%%%%%%InSTA2015の論文\chapter{I/Oテストデータパターンを使ったテストケースの特定方法}

\section{I/Oテストデータパターンを使った仕様項目特定の方法}
３章では，テスト実行時のデータのI/O に着目し，テストベースを分析する際にテスト実行時のデータI/Oの要素で分解し網羅性を確認する方法を，既存の手法に追加することを提案する．

\subsection{I/Oテストデータパターン}

テストを実行するためには，データをAUTにインプットし，AUTのアウトプットを期待結果と実際の結果で比較する．
テスト実行をするときのデータの入出力（以降I/Oと呼ぶ）は，パターンとして分類できる．
AUTへのデータの入力の方法は，外部からの入力，内部に保持したデータの入力，外部と内部からの入力の3パターンに分類できる．
同じようにAUTからのアウトプット方法は3パターンに集約でき，入出力の組み合わせ数はすべてで9パターンとなる.

たとえば，シンプルな機能の四則演算の計算結果が正しいことを検証するときには，AUTの外部から複数の値を入力し，AUTがそれらの値を計算し，計算結果をAUTの外部にアウトプットする.
これは「外部からのデータ入力，外部へのデータ出力」というパターンになる．

AUTに対するテスト実行時のデータの入出力をまとめたパターンは\ref{fig:D-3-Fig11}のように9パターンに集約できる．
   \begin{figure}[htbp]
 \begin{center}
 \includegraphics[width=10cm]{./image/D-3-Fig5.png}
 \caption{I/Oデータパターンの説明}
 \label{fig:D-3-Fig11}
 \end{center}
  \end{figure}
これをI/Oテストデータパターンと呼ぶ.
I/Oテストデータパターンがテスト実行時のデータの入出力から見た全体集合となる．

P1からP9のI/Oデータパターンは単一の入出力の全体像となる．単一の入出力では，論理的機能構造の入力調整，出力調整，変換，貯蔵を通過する．
P1に分類できるシンプルな四則演算の場合，外部からの入力に対して外部に出力する間に，図〜ref {fig：D-4-Fig7}のように論理的機能構造の入力調整，変換，出力調整を通過する．
この３箇所がテスト分析で特定すべきテスト条件の候補となる．
  \begin{figure}[htbp]
 \begin{center}
 \includegraphics[width=10cm]{./image/D-4-Fig7.png}
 \caption{Fig. 7. An explanation of the I/O data patterns.}
 \label{fig:D-4-Fig7}
 \end{center}
  \end{figure}

しかし，実際に期待結果を確認するチェックポイントは3箇所とは限らない．
なぜなら，入力調整に該当する入力の際に適切な値だけ受け入れることと，変換に該当する計算が適切に行われていることの2つだけであり，出力が適切にされることはチェックポイントとしないといったケースが考えられるためである．


\subsection{これまでの実験データを使った調査}
２章で行った検証実験の結果をI/Oテストデータパターンを使うとどこに分類されるかを調査し，結果を考察した．I/Oテストデータパターンと，テスト条件として特定した論理的機能構造を確認することで，各I/Oデータパターンのデータのフローの中で期待結果を確認するチェックポイントが限られていることが確認できた．

\subsection{サポートと相互作用に関する考察}
論理的機能構造の要素であるサポートと相互作用は，単一の入出力だけではなく，関係する他の処理の呼び出しに着目してテスト条件を特定するための分類である．
サポートは，テスト対象フィーチャでのテスト実行時のアクションによって内部的に呼び出される別の処理の結果確認のことを指している．

一方，相互作用は，テスト実行時のアクションによる副作用を，他フィーチャに対するアクションにて呼び出して確認することを指している．
サポートに該当する仕様項目の特定に使う呼び出しのきっかけと相互作用に該当する仕様項目の特定に使う呼び出しのきっかけを整理して，I/Oテストデータパターンとの対応がわかるようにした．

\subsection{I/Oテストデータパターンを使ったテスト分析の実験}
%これまでの実験では，被験者の学習過程に対する効果を検証してきた．また，AUTは，実験用に作られた小さなサンプルを利用していた．
本章の実験では，現実のプロジェクトで作られたテストケースと，今回提案するI/Oテストデータパターンを使ったテスト分析結果を比較し，手法の効果を分析する．

\subsubsection{実験の目的}
この実験は今回提案しているテストカテゴリにI/Oテストデータパターンを使う手法が，現実のテスト設計と比較して網羅的に仕様項目を特定できることを目的とする．そのために現実のテスト設計の結果と，I/Oテストデータパターンを使った分析結果を比較する．

\subsubsection{実験の題材について}

実験対象のAUTは，実在するオンラインのモバイル写真共有アプリケーションを使った．

\subsubsection{実験の実施手順}
モバイル写真共有アプリケーションの開発にて実際に使われたテストケースと、提案する手法で分析した結果を比較する．
実験での実施手順を次に説明する.
\subsubsection{実際のプロジェクトでのテストケースをテスト条件ごとに整理する}
今回の実験で使う成果物には，テストケースのみであり，テスト分析のアウトプットとなるテスト条件の一覧はなかった．
そのため，テストケースを今回の実験のためにテスト分析でのアウトプットであるテスト条件になるようまとめなおした．

\subsubsection{2)テスト対象フィーチャで使われる入力データ，出力データを明らかにする}
テスト対象フィーチャであるアップロードとグリッドビューのテストベースを分析し，
画像データ，画像の情報、設定データ，外部コマンドを入力データ，出力データとして扱うこととした.

\subsubsection{3)I/Oテストデータパターンを付与する}
特定した入力データと出力データは，2)で明らかにしたテスト条件に対して，入力データ ,出力データというカラムに追記していった．
テスト実行時の追記したデータの流れをシミュレーションし，該当するI/Oテストデータパターンを明らかにした．

\subsubsection{4)論理的機能構造とI/Oテストデータパターンを使ってテストベースを分析する}
I/Oテストデータパターンと既存の分析手法であるテストカテゴリを併用してテスト分析を行った．

\subsection{実験結果の評価}

\subsubsection{1)IOテストデータパターンの効果実証の結果}
テストカテゴリとI/Oテストデータパターンを使ったテストベースの分析を行った結果を図〜ref {fig：D-4-Fig10}に示す．
%今回のテスト対象フィーチャであるUploadとGrandviewの 両方でテストカテゴリとI/Oテストデータパターンを使ったテストベースの分析が適用できた．
%そして，両方のフィーチャにて，現実のAUTに おけるテスト設計と比較し，現場のテスト設計に仕様項目が不足していることが実証できた．
%分類に利用したI/Oテストデータパターンは，P5とP8を除く全てであった．
実プロジェクトの仕様項目との比較をした結果を両者を比較すると，テストカテゴリとI/Oテストデータパターンを利用したテスト分析の結果が実プロジェクトより多くの仕様項目を選択できたことが確認できている．
%Fig. 10. Finding the remainder of each data pattarn between Test-Category and the real project.
   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig10.png}
  \caption{Finding the remainder of each data pattebrn between Test-Category and the real project.}
  \label{fig:D-4-Fig10}
  \end{center}
   \end{figure}

\subsubsection{2)I/Oテストデータパターン毎の出現傾向の評価}

現実のプロジェクトで作られたテストケースとテストカテゴリとI/Oテストデータパターンを使ったテストベースの分析結果をP1からP9の分類で出現割合を比較した結果が，図〜ref {fig：D-4-Fig11}である．
それぞれのI/Oテストデータパターンの選択数の差異を図〜ref {fig：D-4-Fig11}にて確認すると，P1が特にテストカテゴリと実プロジェクトの差異が大きいことがわかる．
P1は外部からの入力を行い，外部に出力する最も単純なパターンであり，単純なパターンの仕様項目がより網羅的に特定できていたことが確認できる．
%Fig. 11. Finding the remainder of each data pattebrn between Test-Category and the real project.
   \begin{figure}[htbp]
  \begin{center}
  \includegraphics[width=10cm]{./image/D-4-Fig11.png}
  \caption{IOテストデータパターンごとの違い}
  \label{fig:D-4-Fig11}
  \end{center}
   \end{figure}


\subsubsection{3)現実のプロジェクトにて不足していた仕様項目}
%
%図〜ref {fig：D-4-Fig10}には，現実のプロジェクトにて不足していた仕様項目をいくつか抜粋して列挙した．これらの仕様項目は，全て今回のデータのI/Oのシミュレーションを行い網羅的にテストベースを確認することで特定できたものである．

不足していた仕様項目には，論理的機能構造の要素別に見てもInput Adjustment, Output Adjustmentといったメッセージが現れることや入力制御といった単純なことを確認する仕様項目でも漏れているものもあることが確認できる．
一般的に，仕様項目のリストを作成せずにテストケースを作った場合，テストケースのままでは数量の多さから網羅すべき仕様項目の見易さが低下するため，仕様項目の数が不足することが多い．
実験結果も同様の傾向となった．

\subsection{終わりに}
　本章では，テスト実行時のデータI/Oの要素で分類し網羅的に分析する方法を提案した．そして，現場のテストプロジェクトのテストケースを使い，提案した方法の実証を試みた．結果的に，提案した方法で特定した仕様項目と実プロジェクトで作られるテストケースと比較して，不足している仕様項目の発見が可能であることが確認できた．I/Oテストデータパターンを活用したテスト分析をするためには，まだ多くのサンプルを入手し，全てのI/Oテストデータパターンをナレッジにする必要がある．ナレッジにすることで，テスト分析にて仕様項目を効率よく特定するルールを確立させていきたい．


%%%%%%%%%%%%%%%%%%%%%%%
%電気学会の論文とSSを参考に。現在は変更における状態を含むテスト網羅尺度とテストケース抽出法の提案をコピー
\section{データ共有タスク間の順序組合せテストケース抽出手法}

%%%%%%%%%%%%%%%%%%%%%%%
\subsection{はじめに}
これまでの研究にて、テストカテゴリを使ったブラックボックステストのためのテスト分析手法を提案してきた。
テストカテゴリを使ったテスト分析では、論理的機能構造という参照モデルを使う。
モデルの要素である入力調整，出力調整，変換，貯蔵、サポート、相互作用でテスト対象をカテゴライズしてテスト条件を特定する。
入力調整，出力調整，変換，貯蔵は、外部観察可能な単一の入出力のみを考慮している分類であり，既出の研究て提案したI/O テストデータパターンで網羅することができる。
しかし、サポートと相互作用は，単一の入出力だけではテスト条件の抽出が出来ない。
なぜなら，サポートと相互作用は，単一の入出力だけではなく，関係する他の処理の呼び出しに着目してテスト条件を抽出するための分類であり，統合して確認すべきテスト条件の抽出が必要だからである。
テストケース数の増加は，単一機能のテストより機能間の統合において問題となる。
この場合のテストケース数は，単一の機能や制御構造の和で求めるのではなく，積となるためである。
それに加え，このテストでは，状態遷移に伴う時系列の組合せのテストも求められることから，テストケース数の爆発問題が生じる。
必要なテストケースの抽出方法とその網羅性に関する研究は多々あるが，多くは機能や制御構造を基にした方法である\cite{Myers,Lee,Grinda,Ostrand}。
状態遷移間の組合せについてはNスイッチカバレージに従ってテストケースを抽出する方法がある。
Nスイッチカバレージとは，状態の遷移をパスとし，N+1個の遷移パスを網羅する基準に従て組合せテストケースを作成する。
N=0では遷移パスの組合せをテストできないためN=1，すなわちS1網羅基準（1スイッチカバレージ）が必要とされている\cite{Beizer}。
しかし，S1網羅基準を満たすテストケース数は，２つの状態遷移間における遷移数の積となり，膨大なテスト工数を必要とする課題になる。
本論文では，機能間の統合における状態遷移間の組合せに着目する。

\subsection{テストケース抽出方法と課題}
S1 網羅基準の課題に対す るアプローチとしては,テストケース数を削減する研究と, 自動化により工数を削減する先行研究がある。
自動化による工数削減の研究は,N-スイッチカバレージ を満たすテストケースを形式仕様から自動生成する方法が 知られている。
この方法は,テスト対象となる IT システム の動作を正確に記述したモデルを定義し,そのモデルから 特定の長さの連続した遷移を抽出する方法である (14) 。
対象システムが運動方程式などに従う一般的なモデルベー ステストと異なり,状態遷移にて生ずるシステムの動的な 振舞いを形式仕様化する必要があり,それが困難であるこ とから一般的な IT システムで適用された例は見当たらない。
生成されるテストケース数は N-スイッチカバレージと 同じであり削減されないので,テストケースが自動抽出さ れても,実行のための操作は人手に頼る部分が残り,作業 工数を合理化できない課題がある。
テストケース数を削減する研究としては,状態遷移の組 合せに対して直交表を応用し2因子間の組合せを中心に, 一部3因子の組合せも抽出する研究がある (15) (16) 。
この方法 は,決定表を用いて機械的に組合せを抽出でき,2 因子間 の組合せ即ち S0 網羅基準は完全に網羅できるが,S1 網羅 基準の網羅は不完全であり,かつその選択基準が用いた直 交表に左右されるため重要なテストケースが漏れる課題が ある。
 本研究は,テストケース数を削減するアプローチに属する。
テストケースを機械的に削減するのでは無く,実践の場における経験から生じるノウハウを用いて削減する。
状態遷移に係る不具合は,定義された状態変数や画面とは別に,内部に保存されたデータが影響していることが知られ ている。
具体的には,状態の制御が状態変数や画面によっ て一意に動作するように設計されていたとしても,内部変 数で保持されたデータが存在すると,これが隠れたサブ状 態となり,設計とは異なる振舞いが生じ不具合となる。
本論文では,このような不具合を見つけ出すために必要なテ ストケースを,DFD,ER 図,CRUD 図といったデータ設計文書を入力情報として使うことで合理的に抽出する方法を提案する。

\section{順序組合せによるテストケース抽出法}
本論文では,状態遷移テスト設計における「S1 網羅基準 ではテストケース数が爆発するが,S0 網羅基準では漏れが 生じる」という課題を解決する手法として順序組合せテス トを提案する。

\subsection{順序組合せテストの概要}
提案する手法は，2タスク間の順序組合せを対象とする．
%データストアを共有しないタスク間の組合せは, マルコフ連鎖を前提として順序組合せテストの対象から除外する．
%データストアを共有していないため，画面遷移あるいは状態遷移は独立しており，S0網羅基準にてテストを行えば十分だと考えられるからである．
2タスク間の順序組合せの抽出は以下のルールを適用する．

\subsection{ルール1：変更タスクの特定}
ルール１を用いて変更タスクとそのデータストアを特定し，拡張CRUD図の変更タスク部分を作成する．

拡張CRUD図とは，テストベースとして与えられたDFD，ER図，CRUD図から$P\{Ta\}$の各$Ta_i$と関連する$So_k$，そして$P\{Ds\}$となる$Ds_j$の関係を追加して作成したものである．


\subsection{ルール2：波及タスクの特定}
ルール2を用いて波及タスク群を特定し，拡張CRUD図へ波及タスク部分を追加し図を完成させる．

先に作成した中間の拡張図から変更タスクの操作が$C$か$U$か$D$であるデータストアに着目する．
着目したデータストアに対してエッジを持つタスクが波及タスクのうち，源泉に出力エッジを持つタスクを波及タスクとして特定する．
特定した波及タスクを拡張CRUD図に追記し完成させる．

完成させた拡張CRUD図の例を表~\ref{excrud}に示す．
% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[t]
  \centering
  \caption{完成した拡張CRUD図の例}
    \begin{tabular}{r|r|r|r|r|r|r}
    \multicolumn{1}{c|}{タスク} & \multicolumn{3}{c|}{データストア} & \multicolumn{3}{c}{源泉} \\
\cline{2-7}    \multicolumn{1}{c|}{} & $Ds_1$ & $Ds_2$ & $Ds_3$ & $So_1$ & $So_2$ & $So_3$ \\
    \hline
    \hline
    $Ta_1[St_1]$ & $CU$ &   &   & $In$ &   &  \\
    \hline
    $Ta_3[St_1]$ &   & $C$ &   & $In$ &   &  \\
    \hline
    $Ta_2[St_1]$ & $R$ &   &   &   & $Out$ &  \\
    \hline
    $Ta_5[St_1]$ &   & $R$U &   &   &   & $Out$ \\
    \end{tabular}%
  \label{excrud}%
\end{table}%

\subsection{ルール3：順序組合せテストケースの抽出}
拡張CRUD図を基に順序組合せのテストケースを抽出し，テストケース表を作成する．
表 ~\ref{TCLISTSAMPLE}にその例を示す．概要の部分は，当該組合せが持つ入力の条件や出力の特性を仕様から抜き出して記載する．

%--------------------------------

%\end{enumerate}

% Table generated by Excel2LaTeX from sheet 'Sheet1'
\begin{table}[t]
  \centering
  \caption{順序組合せテストによる論理的テストケースの例}
    \begin{tabular}{l|l|l}
    No & 論理的テストケース & 順序組合せ \\
    \hline
    1 & 概要 & $Ta_1C \rightarrow Ta_2R$ \\
    \hline
    2 & 概要 & $Ta_1U \rightarrow Ta_2R$ \\
    \hline
    3 & 概要 & $Ta_3C \rightarrow Ta_2R$ \\
    \hline
    4 & 概要 & $Ta_3C \rightarrow Ta_2U$ \\
    \hline
    \end{tabular}%
\label{TCLISTSAMPLE}
\end{table}%


以上の手順で，順序組合せテストに必要なテストケースを抽出する．

\section{順序組合せテストの適用評価}
本節では，旅行代理店向けフライト予約システムの仕様を用いて，3章で述べた実施手順を適用し，順序組合せが抽出できることを確認する．
%本論文では，表~\ref{Featurelist}の新規フライト予約を，変更が入った機能セットとする．
%新規フライト予約からテストケースを抽出するための前提として用意した仕様は，新規フライト予約に関連するDFDとER図（図~\ref{fig:DFD}），CRUD図（表~\ref{CRUD}）とする．
%%DFDに含まれるタスク数 $N$は6，データストア数$M$は2，源泉数$L$は4である．


%\subsection{ルール1：変更タスクの特定}
%テストベースであるDFDに含まれるタスク数$N$は6であるが，変更が入った新規フライト予約の変更タスクは，表~\ref{CRUD}のCRUD図を確認するとフライト検索$Ta_1$とフライト予約$Ta_2$であることがわかる．
%図~\ref{fig:DFD}から，$Ta_1$と$Ta_2$の外部入力を確認する．
%$Ta_1$は，Customer$So_1$からETDとDestinationを外部入力し，$Ta_2$は，Customer$So_1$からFlightNo，Cl$AS$s，Order number，PAXを外部入力している．
%
%続いて，$Ta_1$と$Ta_2$の内部出力を確認する．
%$Ta_1$はFlight info$Ds_1$に対して検索条件を与えているのみで内部入力はしていないため，変更タスク群$P\{Ta\}$からは除外する．
%$Ta_2$がFlight info$Ds_1$で$U$，Booking info$Ds_2$で$C$を行っていることが表~\ref{CRUD}から読み取れる．
%これらから，拡張CRUD図（表~\ref{ECRUD1}）を作る．
%表~\ref{ECRUD1}から，ルール１に適合する$Ta_2/Ds_1U$，$Ta_2/Ds_2C$を特定できる．
%
%\begin{table}[t]
%\caption{フライト予約システムの中間拡張CRUD図}
%\label{ECRUD1}
%\begin{center}
%\begin{tabular}{c||c|c||c|c|c|c}
%\hline
%タスク&\multicolumn{2}{c||}{データストア}&\multicolumn{4}{c}{源泉}\\
%&$Ds_1$&$Ds_2$&$So_1$&$So_2$&$So_3$&$So_4$\\
%\hline\hline
%$Ta_1$&&&&&&\\
%\hline
%$Ta_2$&$U$&$C$&$In$&&&\\
%\hline
%\end{tabular}
%%\halflineskip
%\end{center}


\subsection{考察}
次に提案手法で抽出したタスク間の順序組合せと既出の状態を含む$AP$のテストケースを設計する手法である状態遷移テストで,抽出されるテストケースの比較を行う.状態遷移テストのテストベースとなるフライト予約システムの画面遷移図
%である図~\ref{fig:STD}
を使って,順序組合せが確認できる網羅基準であるS1網羅基準を適用する．
%図~\ref{fig:STD}は，
適用範囲を合わせるために，4章の適用のためのサブセットである新規フライト予約を行うために必要な画面と隣接する画面遷移に該当する範囲の図となっている．
仕様の詳細度合いは，DFD，ER図，CRUD図と画面遷移図では同等にしている．
%それは，画面遷移のイベントでのガード条件に記載したデータがDFDのエッジに記載したデータ，ER図のエンティティの属性と一致していることから確認できる．
S1網羅基準を適用すると28の状態遷移パスとなる．
%この表の提案手法の列には，提案手法で抽出した順序組合せに該当する順序組合せを示した．
%状態遷移パスに対応する提案手法で抽出した順序組合せは28のうち,表~\ref{TCLIST2}テストケースNo.1，2，4，5の4つであった．3-25対応
28の状態遷移パスのうち，対応する提案手法で抽出した順序組合せは，
%表~\ref{TCLIST2}テストケースNo.1，2，4，5の
4つであった．
これらは,本状態遷移図のフライト予約状態での登録イベントを起点にするもののみであった．
順序組合せに該当しない状態遷移パスは，互いのタスクで同一のデータを介して処理をするといったことがない．
例えば，フライト検索をした後にキャンセルをするとフライト予約画面に遷移するパスは，前の処理の結果によって影響を及ぼさない．

S1網羅基準では抽出できないが，本手法によって抽出できたテストケースは，

別の機能セットに含まれるタスクであるため，画面遷移図の網羅では現れない.

\subsection{おわりに}

%本論文では，状態遷移を持つソフトウェアにおいて，変更による変更波及がデータベースや外部変数などの保持データを介して生ずる場合のテストに関して，その網羅基準と，テストケースを抽出する手法を提案した．3-6対応によって修正
本論文では，状態遷移を持つソフトウェアにおいて，変更による変更波及がデータベースや外部変数などの保持データを介して生ずる場合のテストに関して，その網羅基準と,順序組合せテストケースを抽出する手法としてIDAU法を提案した．
DFD，ER図、CRUD図をテストベースとして，3つのルールを適用することでテストが必要な順序組合せを抽出できることを説明した．
提案した手法で組合せが抽出できることを確認するため，フライト予約システムの仕様を具体例にして適用を行った．
最後に従来手法である画面遷移図からS1網羅基準にて抽出した状態遷移パスと提案手法を比較して，テストケース数の削減ができる効果と，S1レベルの画面遷移の網羅では抽出できないテストケースが抽出できる効果を示した．

提案手法に対する今後の取り組みは2つある．
1つは,適用範囲の明確化である.変更のパターン（タスク内の制御ロジックの変更,新しい要素の追加など）に対して,どこまで適用でき,どこからは適用できないかを明らかにする.

もう1つは，今回の提案手法のツール化である．
実際の開発プロジェクトで扱う規模の大きいデータ設計文書に対して本手法を適用する際には，本手法のルールをツール化するといった方法での適用が必要になる．
これらの準備を行い，実践の場に本手法を適用していく．

%%%%%%%%%%%%%%%%%%%%%%%
\section{結論}

%%%%%%%%%%%%%%%%%%%%%%%

%\chapter*{謝辞}
%\addcontentsline{toc}{chapter}{\numberline{}謝辞}
%入力例


\newpage

\addcontentsline{toc}{chapter}{\numberline{}参考文献}
\renewcommand{\bibname}{参考文献}

 \bibliographystyle{sieicej}
\bibliography{mybib1}

\end{document}
